---
---


@article{prajapati2021signature,
  abbr={SigV},
  title={Signature Verification using Convolutional Neural Network and Autoencoder.},
  author={Prajapati, Prakash Ratna and Poudel, Samiksha and Baduwal, Madan and Burlakoti, Subritt and Panday, Sanjeeb Prasad},
  abstract={Signature has been one of the widely used verification biometrics out there. Handwritten signatures are used in cheques, forms, letters, applications, minutes, etc. The Signature of every individual is unique in nature, that is why it is essential that a personâ€™s handwritten signature be uniquely identified. Signature Verification is a widely used method for authenticating any individual during absence. Human verification is prone to inaccuracy and sometimes indecisiveness. This paper presents an investigation of using Convolutional Neural Network (CNN) for Writer-Dependent models in signature verification. Random distortions were generated in genuine images using an autoencoder to get forged signatures, which were passed to the classifier during training. The paper details all the pre-processing steps carried out on the image and shows various test results for changing the number of training sets of images. The average test accuracy for Persian dataset is 83% when the system was trained with 22 genuine images. There was a decrease of 9.4% in accuracy when the model was trained with 9 genuine images.},
  journal={Journal of the Institute of Engineering},
  volume={16},
  number={1},
  year={2021},
  url={https://www.researchgate.net/profile/Madan-Baduwal-2/publication/370658396_Signature_Verification_using_Convolutional_Neural_Network_and_Autoencoder/links/645c93c44353ba3b3b5a16b0/Signature-Verification-using-Convolutional-Neural-Network-and-Autoencoder.pdf},
  pdf={https://www.researchgate.net/profile/Madan-Baduwal-2/publication/370658396_Signature_Verification_using_Convolutional_Neural_Network_and_Autoencoder/links/645c93c44353ba3b3b5a16b0/Signature-Verification-using-Convolutional-Neural-Network-and-Autoencoder.pdf},
  dimensions={true},
  selected={true}
}

@article{baduwal2025hybrid,
  abbr={Hybrid-PolypSeg},
  title={Hybrid (Transformer+ CNN)-based Polyp Segmentation},
  author={Baduwal, Madan},
  abstract={Colonoscopy is still the main method of detection and segmentation of colonic polyps, and recent advancements in deep learning networks such as U-Net, ResUNet, Swin-UNet, and PraNet have made outstanding performance in polyp segmentation. Yet, the problem is extremely challenging due to high variation in size, shape, endoscopy types, lighting, imaging protocols, and ill-defined boundaries (fluid, folds) of the polyps, rendering accurate segmentation a challenging and problematic task. To address these critical challenges in polyp segmentation, we introduce a hybrid (Transformer + CNN) model that is crafted to enhance robustness against evolving polyp characteristics. Our hybrid architecture demonstrates superior performance over existing solutions, particularly in addressing two critical challenges: (1) accurate segmentation of polyps with ill-defined margins through boundary-aware attention mechanisms, and (2) robust feature extraction in the presence of common endoscopic artifacts, including specular highlights, motion blur, and fluid occlusions. Quantitative evaluations reveal significant improvements in segmentation accuracy (Recall improved by 1.76%, i.e., 0.9555, accuracy improved by 0.07%, i.e., 0.9849) and artifact resilience compared to state-of-the-art polyp segmentation methods.},
  journal={arXiv preprint arXiv:2508.09189},
  year={2025},
  month={aug},
  url={https://arxiv.org/abs/2508.09189},
  pdf={https://arxiv.org/pdf/2508.09189},
  dimensions={true},
  selected={true}
}
